{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#from PIL import Image as pil_image\n",
    "#from PIL.ImageDraw import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bb(label_df, img):\n",
    "\n",
    "    for column in label_df.columns:\n",
    "        x = label_df[column]['box'][0]\n",
    "        y = label_df[column]['box'][1]\n",
    "        w = label_df[column]['box'][2] - label_df[column]['box'][0]\n",
    "        h = label_df[column]['box'][3] - label_df[column]['box'][1]\n",
    "\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.putText(img,str(label_df[column]['label']),(x+w+10,y+h),0,0.3,(0,255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('./Flight_5_with_ground_truth/')\n",
    "images = [x for x in files if '.jpg' in x]\n",
    "label_data = [x for x in files if '.json' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, len(images)):\n",
    "    # label_data contains a list of labeling data filenames\n",
    "    with open('./Flight_5_with_ground_truth/'+label_data[x]) as json_data:\n",
    "        boxes = pd.DataFrame(json.load(json_data))\n",
    "\n",
    "    # images contains a list of image filenames\n",
    "    cv_img = cv2.imread('./Flight_5_with_ground_truth/'+images[x])\n",
    "    \n",
    "    #creates bounding boxes\n",
    "    create_bb(boxes, cv_img)\n",
    "    \n",
    "    if x == 1 or x == 699:\n",
    "        cv2.imshow('image',cv_img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "#with open('./Flight_5_with_ground_truth/frame_000000_GT.json') as json_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1280, 1)\n",
      "(1024, 1280, 3)\n",
      "(1024, 1280)\n",
      "(1310720,)\n",
      "[104  98  97 ... 230 226 223]\n",
      "[104 104 104 ... 223 223 223]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy.ndimage import affine_transform\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from PIL import Image as pil_image\n",
    "from PIL.ImageDraw import Draw\n",
    "from os.path import isfile\n",
    "\n",
    "def read_raw_image(p):\n",
    "    return pil_image.open((p))\n",
    "\n",
    "# Read an image as black&white numpy array\n",
    "def read_array(p):\n",
    "    img = read_raw_image(p).convert('L')\n",
    "    return img_to_array(img)\n",
    "\n",
    "test = read_array('./Flight_5_with_ground_truth/frame_000000.tif')\n",
    "test2 = cv2.imread('./Flight_5_with_ground_truth/frame_000000.tif')\n",
    "test3 = np.array(pil_image.open('./Flight_5_with_ground_truth/frame_000000.tif'))\n",
    "#    print('True')\n",
    "print(test.shape)\n",
    "print(test2.shape)\n",
    "print(test3.shape)\n",
    "print(np.ravel(test).shape)\n",
    "print(np.ravel(test3))\n",
    "print(np.ravel(test2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape  = (1024,1280,3)\n",
    "anisotropy = 2.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from scipy.ndimage import affine_transform\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras import backend as K\n",
    "\n",
    "# Read an image as black&white numpy array\n",
    "def read_array(p):\n",
    "    img = read_raw_image(p).convert('L')\n",
    "    return img_to_array(img)\n",
    "\n",
    "def build_transform(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    rotation        = np.deg2rad(rotation)\n",
    "    shear           = np.deg2rad(shear)\n",
    "    rotation_matrix = np.array([[np.cos(rotation), np.sin(rotation), 0], [-np.sin(rotation), np.cos(rotation), 0], [0, 0, 1]])\n",
    "    shift_matrix    = np.array([[1, 0, height_shift], [0, 1, width_shift], [0, 0, 1]])\n",
    "    shear_matrix    = np.array([[1, np.sin(shear), 0], [0, np.cos(shear), 0], [0, 0, 1]])\n",
    "    zoom_matrix     = np.array([[1.0/height_zoom, 0, 0], [0, 1.0/width_zoom, 0], [0, 0, 1]])\n",
    "    shift_matrix    = np.array([[1, 0, -height_shift], [0, 1, -width_shift], [0, 0, 1]])\n",
    "    return np.dot(np.dot(rotation_matrix, shear_matrix), np.dot(zoom_matrix, shift_matrix))\n",
    "\n",
    "# Compute the coordinate transformation required to center the pictures, padding as required.\n",
    "def center_transform(affine, input_shape):\n",
    "    hi, wi = float(input_shape[0]), float(input_shape[1])\n",
    "    ho, wo = float(img_shape[0]), float(img_shape[1])\n",
    "    top, left, bottom, right = 0, 0, hi, wi\n",
    "    if wi/hi/anisotropy < wo/ho: # input image too narrow, extend width\n",
    "        w     = hi*wo/ho*anisotropy\n",
    "        left  = (wi-w)/2\n",
    "        right = left + w\n",
    "    else: # input image too wide, extend height\n",
    "        h      = wi*ho/wo/anisotropy\n",
    "        top    = (hi-h)/2\n",
    "        bottom = top + h\n",
    "    center_matrix   = np.array([[1, 0, -ho/2], [0, 1, -wo/2], [0, 0, 1]])\n",
    "    scale_matrix    = np.array([[(bottom - top)/ho, 0, 0], [0, (right - left)/wo, 0], [0, 0, 1]])\n",
    "    decenter_matrix = np.array([[1, 0, hi/2], [0, 1, wi/2], [0, 0, 1]])\n",
    "    return np.dot(np.dot(decenter_matrix, scale_matrix), np.dot(affine, center_matrix))\n",
    "\n",
    "# Apply an affine transformation to an image represented as a numpy array.\n",
    "def transform_img(x, affine):\n",
    "    matrix   = affine[:2,:2]\n",
    "    offset   = affine[:2,2]\n",
    "    x        = np.moveaxis(x, -1, 0)\n",
    "    channels = [affine_transform(channel, matrix, offset, output_shape=img_shape[:-1], order=1,\n",
    "                                 mode='constant', cval=np.average(channel)) for channel in x]\n",
    "    return np.moveaxis(np.stack(channels, axis=0), 0, -1)\n",
    "\n",
    "# Read an image for validation, i.e. without data augmentation.\n",
    "def read_for_validation(p):\n",
    "    x  = read_array(p)\n",
    "    t  = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    t  = center_transform(t, x.shape)\n",
    "    x  = transform_img(x, t)\n",
    "    x -= np.mean(x, keepdims=True)\n",
    "    x /= np.std(x, keepdims=True) + K.epsilon()\n",
    "    return x,t \n",
    "\n",
    "# Read an image for training, i.e. including a random affine transformation\n",
    "def read_for_training(p):\n",
    "    # changed to use opencv instead of PIL\n",
    "    # x  = read_array(p)\n",
    "    x = cv2.imread(p)\n",
    "    t  = build_transform(\n",
    "            random.uniform(-5, 5),\n",
    "            random.uniform(-5, 5),\n",
    "            random.uniform(0.9, 1.0),\n",
    "            random.uniform(0.9, 1.0),\n",
    "            random.uniform(-0.05*img_shape[0], 0.05*img_shape[0]),\n",
    "            random.uniform(-0.05*img_shape[1], 0.05*img_shape[1]))\n",
    "    t  = center_transform(t, x.shape)\n",
    "    x  = transform_img(x, t)\n",
    "    x = x - np.mean(x, keepdims=True)\n",
    "    x /= np.std(x, keepdims=True) + K.epsilon()\n",
    "    return x,t   \n",
    "\n",
    "# Transform corrdinates according to the provided affine transformation\n",
    "def coord_transform(list, trans):\n",
    "    result = []\n",
    "    for x,y in list:\n",
    "        y,x,_ = trans.dot([y,x,1]).astype(np.int)\n",
    "        result.append((x,y))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0d19bff807b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(data, test_size=200, random_state=1)\n",
    "train += train\n",
    "train += train\n",
    "train += train\n",
    "train += train\n",
    "len(train),len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         ...,\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597]],\n",
       " \n",
       "        [[0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         ...,\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597]],\n",
       " \n",
       "        [[0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         ...,\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         ...,\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597]],\n",
       " \n",
       "        [[0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         ...,\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597]],\n",
       " \n",
       "        [[0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         ...,\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597],\n",
       "         [0.00040597, 0.00040597, 0.00040597]]]),\n",
       " array([[ 1.05370943e+00,  2.14135421e-02, -5.45738824e+01],\n",
       "        [-9.18392171e-02,  2.20606318e+00, -6.16126129e+02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_for_training('./Flight_5_with_ground_truth/frame_000000.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-11ad7969ec27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mval_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Preprocess validation images\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mval_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Preprocess bounding boxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcoords\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from numpy.linalg import inv as mat_inv\n",
    "\n",
    "def show_whale(imgs, per_row=5):\n",
    "    n         = len(imgs)\n",
    "    rows      = (n + per_row - 1)//per_row\n",
    "    cols      = min(per_row, n)\n",
    "    fig, axes = plt.subplots(rows,cols, figsize=(24//per_row*cols,24//per_row*rows))\n",
    "    for ax in axes.flatten(): ax.axis('off')\n",
    "    for i,(img,ax) in enumerate(zip(imgs, axes.flatten())): ax.imshow(img.convert('RGB'))\n",
    "\n",
    "val_a = np.zeros((len(val),)+img_shape,dtype=K.floatx()) # Preprocess validation images \n",
    "val_b = np.zeros((len(val),4),dtype=K.floatx()) # Preprocess bounding boxes\n",
    "for i,(p,coords) in enumerate(tqdm_notebook(val)):\n",
    "    img,trans      = read_for_validation(p)\n",
    "    coords         = coord_transform(coords, mat_inv(trans))\n",
    "    x0,y0,x1,y1    = bounding_rectangle(coords)\n",
    "    val_a[i,:,:,:] = img\n",
    "    val_b[i,0]     = x0\n",
    "    val_b[i,1]     = y0\n",
    "    val_b[i,2]     = x1\n",
    "    val_b[i,3]     = y1\n",
    "\n",
    "idx  = 1\n",
    "img  = array_to_img(val_a[idx])\n",
    "img  = img.convert('RGB')\n",
    "draw = Draw(img)\n",
    "draw.rectangle(val_b[idx], outline='red')\n",
    "show_whale([read_raw_image(val[idx][0]), img], per_row=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class TrainingData(Sequence):\n",
    "    def __init__(self, batch_size=32):\n",
    "        super(TrainingData, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "    def __getitem__(self, index):\n",
    "        start = self.batch_size*index;\n",
    "        end   = min(len(train), start + self.batch_size)\n",
    "        size  = end - start\n",
    "        a     = np.zeros((size,) + img_shape, dtype=K.floatx())\n",
    "        b     = np.zeros((size,4), dtype=K.floatx())\n",
    "        for i,(p,coords) in enumerate(train[start:end]):\n",
    "            img,trans   = read_for_training(p)\n",
    "            coords      = coord_transform(coords, mat_inv(trans))\n",
    "            x0,y0,x1,y1 = bounding_rectangle(coords)\n",
    "            a[i,:,:,:]  = img\n",
    "            b[i,0]      = x0\n",
    "            b[i,1]      = y0\n",
    "            b[i,2]      = x1\n",
    "            b[i,3]      = y1\n",
    "        return a,b\n",
    "    def __len__(self):\n",
    "        return (len(train) + self.batch_size - 1)//self.batch_size\n",
    "\n",
    "random.seed(1)\n",
    "a, b = TrainingData(batch_size=5)[1]\n",
    "img  = array_to_img(a[0])\n",
    "img  = img.convert('RGB')\n",
    "draw = Draw(img)\n",
    "draw.rectangle(b[0], outline='red')\n",
    "show_whale([read_raw_image(train[0][0]), img], per_row=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_path(p):\n",
    "    if isfile('./train/' + p): return './train/' + p\n",
    "    if isfile('./test/' + p): return './test/' + p\n",
    "    return p\n",
    "\n",
    "def read_raw_image(p):\n",
    "    return pil_image.open(expand_path(p))\n",
    "\n",
    "def draw_dot(draw, x, y):\n",
    "    draw.ellipse(((x-5,y-5),(x+5,y+5)), fill='red', outline='red')\n",
    "\n",
    "def draw_dots(draw, coordinates):\n",
    "    for x,y in coordinates: draw_dot(draw, x, y)\n",
    "\n",
    "def bounding_rectangle(list):\n",
    "    x0, y0 = list[0]\n",
    "    x1, y1 = x0, y0\n",
    "    for x,y in list[1:]:\n",
    "        x0 = min(x0, x)\n",
    "        y0 = min(y0, y)\n",
    "        x1 = max(x1, x)\n",
    "        y1 = max(y1, y)\n",
    "    return x0,y0,x1,y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
